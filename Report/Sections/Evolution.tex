\section{Evolution}
\label{Evolution}

Evolutionary programming\cite{IoEC, eiben2002evolutionary} is based on the "survival of the fittest" way of nature. If we can determine the quality of an object through a function (also called the \textit{fitness function}), it is possible to improve on an object over time.

We do this by creating an initial population of objects. From this population, we choose candidates according to the \textit{selection strategy} (usually based on the fitness function) and use them to seed the next generation. When the next generation comes around, \textit{offspring} will be spawned from the chosen candidates (called "parents") and added to the population. Candidates for the next generation are selected from the current population, new offsprings are created and a new generation comes around. This way good candidates will survive and reproduce continuously, until a set quality, or some other condition (e.g. number of generations or barely any quality improvement over the last few generations), is reached.

A simple \textit{selection strategy} would be to always select the highest scoring candidates. The problem with this strategy, is that the evolution may get stuck in a \textit{local optima}. This essentially means that no matter how the best candidates are changed we will never find better solutions and because we always select the best candidates, we never get to try other opportunities. \citeauthor{rocha1999preventing}\cite{rocha1999preventing} suggests that parents for the next population should be chosen using a stochastic method, where a candidate's chance of being selected is based on its ranking compared to other candidates. While it does not completely remove the problem of hitting a local optima, it does alleviate it to some degree.

When it comes to spawning \textit{offspring}, there are two ways to do it\cite[Chapter 2]{PCGBook}. \textit{Recombination} selects two or more parents at random and combine their values (according to some function) to form one or more new offspring. \textit{Mutation} selects a parent and creates an offspring where one or more pieces have been randomly changed (usually within set boundaries). 

While our main idea was to compare MOEA and CNS, we decided that we wanted to see how a normal evolution compared to the other two methods. For this purpose, we implemented an evolutionary algorithm that allows for choosing between two selection strategies (highest fitness and chance based) and the two offspring strategies (mutation and recombination). 

The fitness function we use is discussed in section \ref{MapFitness}. The fitness the EA attempts to optimize is the sum of all the part of the fitness function.