\section{Multi-Objective Evolutionary Algorithm}
\label{methodology_moea}
While the standard genetic algorithm seeks to optimize a single objective function, a multi-objective evolutionary algorithms (MOEA) bases its fitness on two or more fitness functions. This is because it is infeasible, for some problems, to combine all interesting features into a single fitness function. An example of this is the basic need for food and water for humans. Most fitness functions would reduce the problem to \textit{amount of food} + {amount of water}. This is infeasible, however, as humans cannot function without water and/or food. Therefore for any solution to be feasible, it is necessary for it to provide both enough food and water for a human to survive. During the evolution process, multi-objective evolutionary algorithms focuses on finding solutions that are \textit{non-dominated solutions} (a solution is dominated when there is at least one other solution "that is better in at least one objective and worse in none."\cite{Togelius2013Controllable}). In the case of food and water for a human, for any solution to dominate another, it must provide at least as much food and water as the solution it dominates, and must provide more of either food or water.

Multiple MOEAs have been suggested over the past twenty years\cite{Deb2001Multi, Fonseca1993Genetic, Srinivas1994Muiltiobjective}. One of the first ones was the \textit{nondominated sorting genetic algorithm (NSGA)}\cite{Srinivas1994Muiltiobjective}, but it was critized for having a \textit{high computational complexity in its sorting}, a \textit{lack of elitism}\footnote{Elitism choses the best candidates from the current generation and carries them over, unchanged, to the next generation.} and the fact that a \textit{sharing parameter} had to be specified. An improved version (\textit{nondominated sorting genetic algorithm II (NSGA-II)}) was proposed by \citeauthor{Deb2000Fast}\cite{Deb2000Fast} in \citeyear{Deb2000Fast}. NSGA-II reduced the overall complexity from $O(M N^3)$ ($M$ being the number of objectives and $N$ being the size of the population) to $O(M N^2)$, added an elitist strategy and made away with the sharing parameter by calculating distances based on the different objectives' parameters.

We have modified the NSGA-II algorithm slightly in order to enforce elitism for our search. We found an edge case where there were more nondominated solutions that the population size, which meant that parents for the next generation were chosen based on distance among those solutions. This sometimes resulted in losing the highest fitness individual, as other solutions would be chosen as parents before it would. We changed the parent selection step to always select the highest fitness individual before selecting other individuals, in the case that there were more nondominated solutions than the population size allowed.

Using multi-objective evolutionary algorithms is a solid approach to StarCraft map generation, as there are multiple objectives to optimize when generating a good map, such as distance between starting bases, number of choke points, how easily it is to defend a starting position, and the number of expansions available to players. Considering how our primary focus was on the speed-versus-balance-tradeoff, we have chosen to use NSGA-II as the MOEA of our choice.