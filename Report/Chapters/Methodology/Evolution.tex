\section{Evolution}
\label{methodology_evolution}

Evolutionary programming\cite{eiben2008introduction, eiben2002evolutionary} is based on the "survival of the fittest" way of nature. As long as the quality of an object can be determined, it is possible to make changes in order to improve the quality of said object. The quality can be determined through the use of a \textit{fitness function}, which described how good an object is based on different criteria.

Evolution starts out with an initial population of objects. From this population, a number of candidates are chosen according to the \textit{selection strategy} and used as \textit{parents} for the next generation. In the next generation, offspring are spawned from the selected parents. Based on a selection strategy, a new population is formed from the population of the previous generation and the spawned offspring. This process is repeated until a a set quality, or some other condition (e.g. number of generations or barely any quality improvement over the last few generations), is reached.

A simple \textit{selection strategy} would be to always select the candidates with highest fitness. This guarantees elitism\footnote{Elitism means choosing the bet candidate(s) from the current generation and carrying them over to the next generation, unchanged.}, but also means that the evolution may get stuck in a \textit{local optima}. This essentially means that no matter how the best candidates are changed, better solutions will never be found and because the best candidates always are selected as parents, other opportunities will never be explored. \citeauthor{rocha1999preventing}\cite{rocha1999preventing} suggests that parents for the next population should be chosen using a stochastic method, where a candidate's chance of being selected is based on its ranking compared to other candidates. While it does not completely remove the problem of getting stuck in a local optima, it does alleviate it to some degree. A third option would be to use \textit{tournament selection}, which is a combination of the two methods above. In \textit{tournament selection}, a random candidate is selected. Another candidate is then selected, also at random, and the fitness of the two is compared. The one with the highest fitness is the winner. This happens a set number of times, after which the strongest will have "eliminated" the weaker ones and will go on to become a candidate for the next population.

When it comes to spawning \textit{offspring}, there are two ways to do it\cite[Chapter 2]{shaker2015procedural}. \textit{Recombination} selects two or more parents at random and combine their values (according to some function) to form one or more new offspring. \textit{Mutation} selects a parent and creates an offspring where one or more values have been randomly changed (usually within a set of boundaries). 

As part of the goal of exploring both evolutionary and novelty search methods, a standard genetic algorithm was implemented. The algorithm uses a stochastic selection strategy and uses mutation as the variation operator. The fitness value of an individual in the evolutionary algorithm is the sum of all of the different fitness measures described in section \ref{methodology_mapfitness}.