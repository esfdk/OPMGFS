\section{Evolution}
\label{methodology_evolution}

Evolutionary programming\cite{eiben2008introduction, eiben2002evolutionary} is based on the "survival of the fittest" way of nature. If we can determine the quality of an object through a function (also called the \textit{fitness function}), it is possible to improve on an object over time.

We do this by creating an initial population of objects. From this population, we choose candidates according to the \textit{selection strategy} (usually based on the fitness function) and use them to seed the next generation. When the next generation comes around, \textit{offspring} will be spawned from the chosen candidates (called "parents") and added to the population. Candidates for the next generation are selected from the current population, new offspring are created and a new generation comes around. This way good candidates will survive and reproduce continuously, until a set quality, or some other condition (e.g. number of generations or barely any quality improvement over the last few generations), is reached.

A simple \textit{selection strategy} would be to always select the highest scoring candidates. The problem with this strategy is that the evolution may get stuck in a \textit{local optima}. This essentially means that no matter how the best candidates are changed we will never find better solutions and because we always select the best candidates, we never get to try other opportunities. \citeauthor{rocha1999preventing}\cite{rocha1999preventing} suggests that parents for the next population should be chosen using a stochastic method, where a candidate's chance of being selected is based on its ranking compared to other candidates. While it does not completely remove the problem of hitting a local optima, it does alleviate it to some degree. A third option would be to use \textit{tournament selection}, which is a combination of the two methods above. In \textit{tournament selection}, a random candidate is selected. Another candidate is then selected, also at random, and the fitness of the two is compared. The one with the highest fitness is the winner. This happens a set number of times, after which the strongest will have "eliminated" the weaker ones and will go on to become a candidate for the next population.

When it comes to spawning \textit{offspring}, there are two ways to do it\cite[Chapter 2]{shaker2015procedural}. \textit{Recombination} selects two or more parents at random and combine their values (according to some function) to form one or more new offspring. \textit{Mutation} selects a parent and creates an offspring where one or more pieces have been randomly changed (usually within set boundaries). 

As part of the goal of exploring both evolutionary and novelty search methods, a standard genetic algorithm was implemented. The tests will include two types of selection strategies (highest fitness and chance based) using mutation as the variation operator. The fitness value of an individual in the evolutionary algorithm is the sum of all of the different fitness measures described in section \ref{methodology_mapfitness}.